{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2C - CartPole\n",
    "Implementation of the A2C RL Algorithm for the OpenAI's Gym environment CartPole-V1 (not in parallel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value Fuction Estimator\n",
    "class Critic(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        self.fc1 = tf.keras.layers.Dense(units=32, input_shape=[8,], activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(units=8, activation='relu')\n",
    "        self.out = tf.keras.layers.Dense(units=1, activation='relu')\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action Value Fuction Estimator (q-network)\n",
    "class Actor(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Actor, self).__init__()\n",
    "        \n",
    "        # 64(share) -> 64(share) -> 32 -> 32 -> mu(tanh) [-1,1]\n",
    "        # 64(share) -> 64(share) -> 32 -> 32 -> sigma(sigmoid) [0,1]\n",
    "        self.sharedFC1 = tf.keras.layers.Dense(units=64, input_shape=[8,], activation='relu')\n",
    "        self.sharedFC2 = tf.keras.layers.Dense(units=64, activation='relu')\n",
    "        \n",
    "        self.muFC1 = tf.keras.layers.Dense(units=32, activation='relu')\n",
    "        self.muFC2 = tf.keras.layers.Dense(units=32, activation='relu')\n",
    "        \n",
    "        self.sigmaFC1 = tf.keras.layers.Dense(units=32, activation='relu')\n",
    "        self.sigmaFC2 = tf.keras.layers.Dense(units=32, activation='relu')\n",
    "        \n",
    "        \n",
    "        self.mu_out = tf.keras.layers.Dense(units=1, activation='tanh')\n",
    "        self.sigma_out = tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = tf.convert_to_tensor(x)\n",
    "        x = self.sharedFC1(x)\n",
    "        x = self.sharedFC2(x)\n",
    "        \n",
    "        mu = self.muFC1(x)\n",
    "        mu = self.muFC2(mu)\n",
    "        mu = self.mu_out(mu)\n",
    "        \n",
    "        sigma = self.sigmaFC1(x)\n",
    "        sigma = self.sigmaFC2(sigma)\n",
    "        sigma = self.sigma_out(sigma)     \n",
    "        \n",
    "        return (mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alex/gym/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28530455 1.1542523 ]\n",
      "[ 0.245451   -0.44724196]\n",
      "[-0.38074675  0.08604362]\n",
      "[-0.14134149 -0.60266405]\n",
      "[0.27019036 0.1077247 ]\n",
      "[-1.1040916   0.05945595]\n",
      "[-0.09902799 -0.3725792 ]\n",
      "[-0.36259574 -0.75470775]\n",
      "[-0.24704966  0.9929735 ]\n",
      "[-0.35394356 -0.48451877]\n",
      "[0.0257036  0.54721546]\n",
      "[-0.06890254  0.32277626]\n",
      "[-0.4002181   0.30130306]\n",
      "[ 0.43381265 -0.23089729]\n",
      "[0.46184132 0.23931234]\n",
      "[0.1635864  0.35165933]\n",
      "[0.54420996 0.5298963 ]\n",
      "[-0.04836908 -0.12592994]\n",
      "[-0.03511038  0.1852528 ]\n",
      "[-1.1173435  -0.24602829]\n",
      "[-0.01030482  0.40038556]\n",
      "[ 0.42590514 -0.63675827]\n",
      "[0.35714528 0.154502  ]\n",
      "[0.81446916 0.42151278]\n",
      "[0.18502414 0.9310327 ]\n",
      "[-0.5011111   0.10578859]\n",
      "[-0.03380073 -0.40437925]\n",
      "[-0.56764567 -0.10875219]\n",
      "[ 0.1087542  -0.66132253]\n",
      "[0.29736346 0.12485707]\n",
      "[0.24273135 0.0116913 ]\n",
      "[-0.31810665 -0.33983552]\n",
      "[0.05975203 1.4467914 ]\n",
      "[0.31143478 0.9642538 ]\n",
      "[0.5935407  0.62621677]\n",
      "[ 0.25494638 -0.18613185]\n",
      "[-0.00828307 -0.24017277]\n",
      "[0.3883799 0.3455398]\n",
      "[-0.98170143 -0.5537721 ]\n",
      "[-0.29493386  0.3472094 ]\n",
      "[0.6418306  0.34705484]\n",
      "[-1.0251176  -0.35626206]\n",
      "[-0.05520092  0.33240387]\n",
      "[-0.08294747  0.8894854 ]\n",
      "[-0.38080367 -0.37467688]\n",
      "[-0.13860111 -0.35892177]\n",
      "[-0.6090955  0.66614  ]\n",
      "[ 0.7610394  -0.07085335]\n",
      "[0.16525106 0.09887803]\n",
      "[ 0.24904546 -0.13076821]\n",
      "[-0.10210496 -0.27852118]\n",
      "[0.5950508  0.00812374]\n",
      "[ 0.40316907 -1.1213459 ]\n",
      "[-0.14975546  0.02741088]\n",
      "[ 0.9324909 -0.8580407]\n",
      "[0.5351028 0.9467109]\n",
      "[ 0.08003533 -0.33281842]\n",
      "[0.45863348 0.1189848 ]\n",
      "[0.78468275 0.554428  ]\n",
      "[ 0.11154401 -0.8121815 ]\n",
      "[0.4094168  0.12480501]\n",
      "[-0.2820464  -0.29876372]\n",
      "[0.72442263 0.07970508]\n",
      "[0.6908101  0.17888823]\n",
      "[-0.0596081   0.35648754]\n",
      "[ 0.72011137 -0.57915395]\n",
      "[ 0.6568833  -0.42983383]\n",
      "[-0.42925087 -0.25886515]\n",
      "[-0.59252834  0.07274833]\n",
      "[ 0.22982173 -0.5548755 ]\n",
      "[ 1.0176967  -0.07216389]\n",
      "[-0.23089625  0.44149762]\n",
      "[-0.15574539 -0.5047712 ]\n",
      "[ 0.19876766 -0.55782086]\n",
      "[ 0.25795764 -0.11546206]\n",
      "[-0.6787774  1.0491813]\n",
      "[0.5203395 0.7878461]\n",
      "[0.04342311 0.22474344]\n",
      "[ 1.3612118 -0.8906593]\n",
      "[ 0.02421451 -0.38576186]\n",
      "[-0.16723175  0.6613633 ]\n",
      "[-0.4693836   0.00122086]\n",
      "[-0.64309376  0.6837077 ]\n",
      "[0.24025533 0.25989497]\n",
      "[-0.24036206  0.7438025 ]\n",
      "[ 0.3107428 -1.0375226]\n",
      "[ 0.07855049 -0.16172859]\n",
      "Episode 1 of 100 findished after 87 timesteps\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Received a label value of -1 which is outside the valid range of [0, 1).  Label values: 0 -1 [Op:SparseSoftmaxCrossEntropyWithLogits]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f41361124855>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;31m# Compute the actor loss (log part of the policy gradient)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mactor_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_sparse_ce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madvantages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;31m# Compute gradient with respect to the parameters of the actor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mpolicy_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    124\u001b[0m         y_true, y_pred, sample_weight)\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope_name\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m       \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m       return losses_utils.compute_weighted_loss(\n\u001b[1;32m    128\u001b[0m           losses, sample_weight, reduction=self._get_reduction())\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    219\u001b[0m       y_pred, y_true = tf_losses_util.squeeze_or_expand_dimensions(\n\u001b[1;32m    220\u001b[0m           y_pred, y_true)\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, axis)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msparse_categorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m   return K.sparse_categorical_crossentropy(\n\u001b[0;32m--> 978\u001b[0;31m       y_true, y_pred, from_logits=from_logits, axis=axis)\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   4574\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4575\u001b[0m     res = nn.sparse_softmax_cross_entropy_with_logits_v2(\n\u001b[0;32m-> 4576\u001b[0;31m         labels=target, logits=output)\n\u001b[0m\u001b[1;32m   4577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4578\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mupdate_shape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moutput_rank\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits_v2\u001b[0;34m(labels, logits, name)\u001b[0m\n\u001b[1;32m   3535\u001b[0m   \"\"\"\n\u001b[1;32m   3536\u001b[0m   return sparse_softmax_cross_entropy_with_logits(\n\u001b[0;32m-> 3537\u001b[0;31m       labels=labels, logits=logits, name=name)\n\u001b[0m\u001b[1;32m   3538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[1;32m   3455\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3456\u001b[0m       cost, _ = gen_nn_ops.sparse_softmax_cross_entropy_with_logits(\n\u001b[0;32m-> 3457\u001b[0;31m           precise_logits, labels, name=name)\n\u001b[0m\u001b[1;32m   3458\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3459\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[0;34m(features, labels, name)\u001b[0m\n\u001b[1;32m  10819\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10820\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10821\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10822\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10823\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6605\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6606\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6607\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Received a label value of -1 which is outside the valid range of [0, 1).  Label values: 0 -1 [Op:SparseSoftmaxCrossEntropyWithLogits]"
     ]
    }
   ],
   "source": [
    "# Prepare Tensorboard\n",
    "!rm -rf ./logs/\n",
    "current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "#%tensorboard --logdir logs/\n",
    "#tf.keras.backend.clear_session()\n",
    "# Initialize cart pole environment\n",
    "env = gym.make('LunarLanderContinuous-v2')\n",
    "# Initialize model, loss and optimizer\n",
    "actor = Actor()\n",
    "critic = Critic()\n",
    "actor_optimizer = tf.keras.optimizers.Adam()\n",
    "critic_optimizer = tf.keras.optimizers.Adam()\n",
    "mse = tf.keras.losses.MSE\n",
    "weighted_sparse_ce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# Initialize replay memory\n",
    "observations = []\n",
    "# Set hyperparameters\n",
    "discount = 0.95\n",
    "max_time_steps = 500\n",
    "num_episodes = 100\n",
    "\n",
    "step = 0\n",
    "# Run for agent and environment for num_episodes\n",
    "for i_episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    #breakpoint()\n",
    "    \n",
    "    # Agent has 500 trials at max, if it does not fail beforehand\n",
    "    for t in range(max_time_steps):\n",
    "#        env.render()\n",
    "        # Compute action\n",
    "        state = np.reshape(state, [1,8])\n",
    "        mu, sigma = actor(state)\n",
    "        \n",
    "        # sample two values from normal distribution\n",
    "        action = tf.random.normal((2,), mean=mu, stddev=sigma)\n",
    "        action = np.reshape(action, (2,))\n",
    "        # Execute action and store action, state and reward\n",
    "        print(action)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        observations.append((state, action, reward))\n",
    "        state = next_state\n",
    "        \n",
    "        # Interrupt the trial if the agent fails\n",
    "        if done:\n",
    "            break\n",
    "        step += 1\n",
    "        \n",
    "    print(f\"Episode {i_episode + 1} of {num_episodes} findished after {t+1} timesteps\")\n",
    "        \n",
    "    # Store losses temporary\n",
    "    losses = []\n",
    "    # Initialize variable for the estimated return\n",
    "    estimated_return = 0 if done else critic(next_state)\n",
    "    \n",
    "    # Iterate over taken actions and observed states and rewards\n",
    "    observations.reverse()\n",
    "    for state, action, reward in observations:\n",
    "        # Compute estimated return\n",
    "        estimated_return = discount * estimated_return + reward\n",
    "        # Compute state value\n",
    "        state_v = critic(state)\n",
    "    \n",
    "        # Compute gradients for the actor (policy gradient)\n",
    "        # Maximize the estimated return\n",
    "        with tf.GradientTape() as actor_tape:\n",
    "            logits = tf.math.log(actor(state))\n",
    "            advantages = estimated_return - int(state_v)\n",
    "            advantages = tf.cast([[advantages]], tf.float32)\n",
    "            action = tf.cast(action, tf.int32)\n",
    "            # Compute the actor loss (log part of the policy gradient)\n",
    "            actor_loss = weighted_sparse_ce(action, logits, sample_weight=advantages)\n",
    "            # Compute gradient with respect to the parameters of the actor            \n",
    "            policy_gradients = actor_tape.gradient(actor_loss, actor.trainable_variables)\n",
    "\n",
    "        # Compute gradients for the critic\n",
    "        # minimize MSE for the state value function\n",
    "        with tf.GradientTape() as critic_tape:\n",
    "            state_v = critic(state)\n",
    "            # Compute the loss\n",
    "            critic_loss = mse(estimated_return, state_v)\n",
    "            # Compute the gradient\n",
    "            critic_gradients = critic_tape.gradient(critic_loss, critic.trainable_variables)\n",
    "            #breakpoint()\n",
    "            # Accumulate gradients\n",
    "            #critic_gradients.append(gradients)\n",
    "            \n",
    "        # Apply gradients.\n",
    "        actor_optimizer.apply_gradients(zip(policy_gradients, actor.trainable_variables))\n",
    "        critic_optimizer.apply_gradients(zip(critic_gradients, critic.trainable_variables))\n",
    "        losses.append(actor_loss)\n",
    "\n",
    "    observations = []\n",
    "\n",
    "    # Store summary statistics\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('?b', tf.reduce_mean(losses), step=step)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(2,)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
