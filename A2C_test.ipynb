{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2C - CartPole\n",
    "Implementation of the A2C RL Algorithm for the OpenAI's Gym environment CartPole-V1 (not in parallel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action Value Fuction Estimator (q-network)\n",
    "class Critic(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        self.fc1 = tf.keras.layers.Dense(units=16, input_shape=[4,], activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(units=8, activation='relu')\n",
    "        self.out = tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action Value Fuction Estimator (q-network)\n",
    "class Actor(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Actor, self).__init__()\n",
    "        self.fc1 = tf.keras.layers.Dense(units=16, input_shape=[4,], activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(units=8, activation='relu')\n",
    "        self.out = tf.keras.layers.Dense(units=2, activation='softmax')\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = tf.convert_to_tensor(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 13371), started 4:33:34 ago. (Use '!kill 13371' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2c0ff44c6e82dba5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2c0ff44c6e82dba5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer actor_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/.venv/tensorflow-gpu/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 of 200 findished after 22 timesteps\n",
      "WARNING:tensorflow:Layer critic_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Episode 2 of 200 findished after 11 timesteps\n",
      "Episode 3 of 200 findished after 40 timesteps\n",
      "Episode 4 of 200 findished after 13 timesteps\n",
      "Episode 5 of 200 findished after 16 timesteps\n",
      "Episode 6 of 200 findished after 18 timesteps\n",
      "Episode 7 of 200 findished after 25 timesteps\n",
      "Episode 8 of 200 findished after 17 timesteps\n",
      "Episode 9 of 200 findished after 12 timesteps\n",
      "Episode 10 of 200 findished after 19 timesteps\n",
      "Episode 11 of 200 findished after 17 timesteps\n",
      "Episode 12 of 200 findished after 27 timesteps\n",
      "Episode 13 of 200 findished after 21 timesteps\n",
      "Episode 14 of 200 findished after 32 timesteps\n",
      "Episode 15 of 200 findished after 14 timesteps\n",
      "Episode 16 of 200 findished after 12 timesteps\n",
      "Episode 17 of 200 findished after 19 timesteps\n",
      "Episode 18 of 200 findished after 16 timesteps\n",
      "Episode 19 of 200 findished after 32 timesteps\n",
      "Episode 20 of 200 findished after 13 timesteps\n",
      "Episode 21 of 200 findished after 16 timesteps\n",
      "Episode 22 of 200 findished after 11 timesteps\n",
      "Episode 23 of 200 findished after 22 timesteps\n",
      "Episode 24 of 200 findished after 12 timesteps\n",
      "Episode 25 of 200 findished after 20 timesteps\n",
      "Episode 26 of 200 findished after 25 timesteps\n",
      "Episode 27 of 200 findished after 24 timesteps\n",
      "Episode 28 of 200 findished after 11 timesteps\n",
      "Episode 29 of 200 findished after 16 timesteps\n",
      "Episode 30 of 200 findished after 10 timesteps\n",
      "Episode 31 of 200 findished after 25 timesteps\n",
      "Episode 32 of 200 findished after 13 timesteps\n",
      "Episode 33 of 200 findished after 16 timesteps\n",
      "Episode 34 of 200 findished after 15 timesteps\n",
      "Episode 35 of 200 findished after 13 timesteps\n",
      "Episode 36 of 200 findished after 17 timesteps\n",
      "Episode 37 of 200 findished after 18 timesteps\n",
      "Episode 38 of 200 findished after 12 timesteps\n",
      "Episode 39 of 200 findished after 16 timesteps\n",
      "Episode 40 of 200 findished after 13 timesteps\n",
      "Episode 41 of 200 findished after 22 timesteps\n",
      "Episode 42 of 200 findished after 15 timesteps\n",
      "Episode 43 of 200 findished after 10 timesteps\n",
      "Episode 44 of 200 findished after 19 timesteps\n",
      "Episode 45 of 200 findished after 17 timesteps\n",
      "Episode 46 of 200 findished after 19 timesteps\n",
      "Episode 47 of 200 findished after 48 timesteps\n",
      "Episode 48 of 200 findished after 16 timesteps\n",
      "Episode 49 of 200 findished after 15 timesteps\n",
      "Episode 50 of 200 findished after 14 timesteps\n",
      "Episode 51 of 200 findished after 42 timesteps\n",
      "Episode 52 of 200 findished after 21 timesteps\n",
      "Episode 53 of 200 findished after 14 timesteps\n",
      "Episode 54 of 200 findished after 27 timesteps\n",
      "Episode 55 of 200 findished after 15 timesteps\n",
      "Episode 56 of 200 findished after 10 timesteps\n",
      "Episode 57 of 200 findished after 12 timesteps\n",
      "Episode 58 of 200 findished after 21 timesteps\n",
      "Episode 59 of 200 findished after 15 timesteps\n",
      "Episode 60 of 200 findished after 16 timesteps\n",
      "Episode 61 of 200 findished after 15 timesteps\n",
      "Episode 62 of 200 findished after 29 timesteps\n",
      "Episode 63 of 200 findished after 21 timesteps\n",
      "Episode 64 of 200 findished after 21 timesteps\n",
      "Episode 65 of 200 findished after 15 timesteps\n",
      "Episode 66 of 200 findished after 29 timesteps\n",
      "Episode 67 of 200 findished after 13 timesteps\n",
      "Episode 68 of 200 findished after 20 timesteps\n",
      "Episode 69 of 200 findished after 17 timesteps\n",
      "Episode 70 of 200 findished after 10 timesteps\n",
      "Episode 71 of 200 findished after 15 timesteps\n",
      "Episode 72 of 200 findished after 39 timesteps\n",
      "Episode 73 of 200 findished after 14 timesteps\n",
      "Episode 74 of 200 findished after 14 timesteps\n",
      "Episode 75 of 200 findished after 34 timesteps\n",
      "Episode 76 of 200 findished after 18 timesteps\n",
      "Episode 77 of 200 findished after 18 timesteps\n",
      "Episode 78 of 200 findished after 33 timesteps\n",
      "Episode 79 of 200 findished after 14 timesteps\n",
      "Episode 80 of 200 findished after 13 timesteps\n",
      "Episode 81 of 200 findished after 17 timesteps\n",
      "Episode 82 of 200 findished after 14 timesteps\n",
      "Episode 83 of 200 findished after 23 timesteps\n",
      "Episode 84 of 200 findished after 21 timesteps\n",
      "Episode 85 of 200 findished after 10 timesteps\n",
      "Episode 86 of 200 findished after 27 timesteps\n",
      "Episode 87 of 200 findished after 17 timesteps\n",
      "Episode 88 of 200 findished after 33 timesteps\n",
      "Episode 89 of 200 findished after 33 timesteps\n",
      "Episode 90 of 200 findished after 29 timesteps\n",
      "Episode 91 of 200 findished after 20 timesteps\n",
      "Episode 92 of 200 findished after 30 timesteps\n",
      "Episode 93 of 200 findished after 33 timesteps\n",
      "Episode 94 of 200 findished after 24 timesteps\n",
      "Episode 95 of 200 findished after 18 timesteps\n",
      "Episode 96 of 200 findished after 20 timesteps\n",
      "Episode 97 of 200 findished after 16 timesteps\n",
      "Episode 98 of 200 findished after 26 timesteps\n",
      "Episode 99 of 200 findished after 10 timesteps\n",
      "Episode 100 of 200 findished after 46 timesteps\n",
      "Episode 101 of 200 findished after 14 timesteps\n",
      "Episode 102 of 200 findished after 21 timesteps\n",
      "Episode 103 of 200 findished after 35 timesteps\n",
      "Episode 104 of 200 findished after 18 timesteps\n",
      "Episode 105 of 200 findished after 9 timesteps\n",
      "Episode 106 of 200 findished after 15 timesteps\n",
      "Episode 107 of 200 findished after 28 timesteps\n",
      "Episode 108 of 200 findished after 23 timesteps\n",
      "Episode 109 of 200 findished after 26 timesteps\n",
      "Episode 110 of 200 findished after 18 timesteps\n",
      "Episode 111 of 200 findished after 16 timesteps\n",
      "Episode 112 of 200 findished after 16 timesteps\n",
      "Episode 113 of 200 findished after 22 timesteps\n",
      "Episode 114 of 200 findished after 16 timesteps\n",
      "Episode 115 of 200 findished after 23 timesteps\n",
      "Episode 116 of 200 findished after 15 timesteps\n",
      "Episode 117 of 200 findished after 19 timesteps\n",
      "Episode 118 of 200 findished after 43 timesteps\n",
      "Episode 119 of 200 findished after 16 timesteps\n",
      "Episode 120 of 200 findished after 15 timesteps\n",
      "Episode 121 of 200 findished after 32 timesteps\n",
      "Episode 122 of 200 findished after 19 timesteps\n",
      "Episode 123 of 200 findished after 10 timesteps\n",
      "Episode 124 of 200 findished after 24 timesteps\n",
      "Episode 125 of 200 findished after 44 timesteps\n",
      "Episode 126 of 200 findished after 12 timesteps\n",
      "Episode 127 of 200 findished after 16 timesteps\n",
      "Episode 128 of 200 findished after 13 timesteps\n",
      "Episode 129 of 200 findished after 34 timesteps\n",
      "Episode 130 of 200 findished after 27 timesteps\n",
      "Episode 131 of 200 findished after 40 timesteps\n",
      "Episode 132 of 200 findished after 22 timesteps\n",
      "Episode 133 of 200 findished after 19 timesteps\n",
      "Episode 134 of 200 findished after 25 timesteps\n",
      "Episode 135 of 200 findished after 14 timesteps\n",
      "Episode 136 of 200 findished after 18 timesteps\n",
      "Episode 137 of 200 findished after 45 timesteps\n",
      "Episode 138 of 200 findished after 12 timesteps\n",
      "Episode 139 of 200 findished after 10 timesteps\n",
      "Episode 140 of 200 findished after 12 timesteps\n",
      "Episode 141 of 200 findished after 12 timesteps\n",
      "Episode 142 of 200 findished after 15 timesteps\n",
      "Episode 143 of 200 findished after 43 timesteps\n",
      "Episode 144 of 200 findished after 26 timesteps\n",
      "Episode 145 of 200 findished after 19 timesteps\n",
      "Episode 146 of 200 findished after 26 timesteps\n",
      "Episode 147 of 200 findished after 16 timesteps\n",
      "Episode 148 of 200 findished after 27 timesteps\n",
      "Episode 149 of 200 findished after 13 timesteps\n",
      "Episode 150 of 200 findished after 16 timesteps\n",
      "Episode 151 of 200 findished after 17 timesteps\n",
      "Episode 152 of 200 findished after 23 timesteps\n",
      "Episode 153 of 200 findished after 20 timesteps\n",
      "Episode 154 of 200 findished after 15 timesteps\n",
      "Episode 155 of 200 findished after 11 timesteps\n",
      "Episode 156 of 200 findished after 15 timesteps\n",
      "Episode 157 of 200 findished after 11 timesteps\n",
      "Episode 158 of 200 findished after 21 timesteps\n",
      "Episode 159 of 200 findished after 41 timesteps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 160 of 200 findished after 26 timesteps\n",
      "Episode 161 of 200 findished after 12 timesteps\n",
      "Episode 162 of 200 findished after 12 timesteps\n",
      "Episode 163 of 200 findished after 17 timesteps\n",
      "Episode 164 of 200 findished after 19 timesteps\n",
      "Episode 165 of 200 findished after 17 timesteps\n",
      "Episode 166 of 200 findished after 18 timesteps\n",
      "Episode 167 of 200 findished after 14 timesteps\n",
      "Episode 168 of 200 findished after 17 timesteps\n",
      "Episode 169 of 200 findished after 16 timesteps\n",
      "Episode 170 of 200 findished after 16 timesteps\n",
      "Episode 171 of 200 findished after 15 timesteps\n",
      "Episode 172 of 200 findished after 9 timesteps\n",
      "Episode 173 of 200 findished after 53 timesteps\n",
      "Episode 174 of 200 findished after 12 timesteps\n",
      "Episode 175 of 200 findished after 18 timesteps\n",
      "Episode 176 of 200 findished after 12 timesteps\n",
      "Episode 177 of 200 findished after 26 timesteps\n",
      "Episode 178 of 200 findished after 12 timesteps\n",
      "Episode 179 of 200 findished after 22 timesteps\n",
      "Episode 180 of 200 findished after 10 timesteps\n",
      "Episode 181 of 200 findished after 10 timesteps\n",
      "Episode 182 of 200 findished after 19 timesteps\n",
      "Episode 183 of 200 findished after 17 timesteps\n",
      "Episode 184 of 200 findished after 9 timesteps\n",
      "Episode 185 of 200 findished after 19 timesteps\n",
      "Episode 186 of 200 findished after 20 timesteps\n",
      "Episode 187 of 200 findished after 27 timesteps\n",
      "Episode 188 of 200 findished after 17 timesteps\n",
      "Episode 189 of 200 findished after 15 timesteps\n",
      "Episode 190 of 200 findished after 14 timesteps\n",
      "Episode 191 of 200 findished after 24 timesteps\n",
      "Episode 192 of 200 findished after 12 timesteps\n",
      "Episode 193 of 200 findished after 13 timesteps\n",
      "Episode 194 of 200 findished after 22 timesteps\n",
      "Episode 195 of 200 findished after 9 timesteps\n",
      "Episode 196 of 200 findished after 20 timesteps\n",
      "Episode 197 of 200 findished after 23 timesteps\n",
      "Episode 198 of 200 findished after 31 timesteps\n",
      "Episode 199 of 200 findished after 18 timesteps\n",
      "Episode 200 of 200 findished after 13 timesteps\n"
     ]
    }
   ],
   "source": [
    "# Prepare Tensorboard\n",
    "!rm -rf ./logs/\n",
    "current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "%tensorboard --logdir logs/\n",
    "#tf.keras.backend.clear_session()\n",
    "# Initialize cart pole environment\n",
    "env = gym.make('CartPole-v1')\n",
    "# Initialize model, loss and optimizer\n",
    "actor = Actor()\n",
    "critic = Critic()\n",
    "actor_optimizer = tf.keras.optimizers.Adam()\n",
    "critic_optimizer = tf.keras.optimizers.Adam()\n",
    "mse = tf.keras.losses.MSE\n",
    "cce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# Initialize replay memory\n",
    "observations = []\n",
    "# Set hyperparameters\n",
    "discount = 0.9\n",
    "max_time_steps = 500\n",
    "num_episodes = 200\n",
    "\n",
    "step = 0\n",
    "# Run for agent and environment for num_episodes\n",
    "for i_episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    #breakpoint()\n",
    "    \n",
    "    # Agent has 500 trials at max, if it does not fail beforehand\n",
    "    for t in range(max_time_steps):\n",
    "        env.render()\n",
    "        # Compute action\n",
    "        state = np.reshape(state, [1,4])\n",
    "        probabilities = actor(state)\n",
    "        action = tf.random.categorical(tf.math.log(probabilities), 1)\n",
    "        #breakpoint()\n",
    "        # Execute action and store action, state and reward\n",
    "        next_state, reward, done, info = env.step(int(action))\n",
    "        observations.append((state, action, reward))\n",
    "        state = next_state\n",
    "        \n",
    "        # Interrupt the trial if the agent fails\n",
    "        if done:\n",
    "            break\n",
    "        step += 1\n",
    "        \n",
    "    print(f\"Episode {i_episode + 1} of {num_episodes} findished after {t+1} timesteps\")\n",
    "        \n",
    "    # Store losses temporary\n",
    "    losses = []\n",
    "\n",
    "    # Initialize variable for the estimated return\n",
    "    estimated_reward = 0 if done else critic(next_state)\n",
    "    \n",
    "    # Iterate over taken actions and observed states and rewards\n",
    "    observations.reverse()\n",
    "    for state, action, reward in observations:\n",
    "        \n",
    "        state = np.reshape(state, [1,4])\n",
    "        # Compute estimated return\n",
    "        estimated_return = discount * estimated_reward + reward\n",
    "        # Compute state value\n",
    "        state_v = critic(state)\n",
    "        \n",
    "        # Compute gradients for the actor (policy gradient)\n",
    "        # Maximize the estimated return\n",
    "        policy_gradients = []\n",
    "        with tf.GradientTape() as actor_tape:\n",
    "            #\n",
    "            logits = tf.math.log(actor(state))\n",
    "            \n",
    "            # Compute the actor loss (log part of the policy gradient)\n",
    "            #actor_loss = cce(tf.cast(action, tf.int32), logits[0])\n",
    "            advantages = estimated_return - int(state_v)\n",
    "            \n",
    "            actor_loss = _logits_loss(action, logits, advantages)\n",
    "            # Compute gradient with respect to the parameters of the actor            \n",
    "            \n",
    "            gradients = actor_tape.gradient(actor_loss, actor.trainable_variables)\n",
    "            #policy_gradients.append(gradients)\n",
    "            # Accumulate gradients\n",
    "            #policy_gradients = policy_gradients + gradients * (estimated_return - state_v)\n",
    "        #breakpoint()\n",
    "        # Compute gradients for the critic\n",
    "        # minimize MSE for the state value function\n",
    "        critic_gradients = []\n",
    "        with tf.GradientTape() as critic_tape:\n",
    "            #\n",
    "            state_v = critic(state)\n",
    "            # Compute the loss\n",
    "            critic_loss = mse(estimated_reward, state_v)\n",
    "            # Compute the gradient\n",
    "            gradients = critic_tape.gradient(critic_loss, critic.trainable_variables)\n",
    "            #breakpoint()\n",
    "            # Accumulate gradients\n",
    "            #critic_gradients.append(gradients)\n",
    "            \n",
    "        # Apply gradients.\n",
    "        actor_optimizer.apply_gradients(zip(policy_gradients, actor.trainable_variables))\n",
    "        critic_optimizer.apply_gradients(zip(critic_gradients, critic.trainable_variables))\n",
    "        losses.append(critic_loss)\n",
    "\n",
    "    observations = []\n",
    "\n",
    "    # Store summary statistics\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('?b', tf.reduce_mean(losses), step=step)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.losses as kls\n",
    "import tensorflow.keras.optimizers as ko\n",
    "  \n",
    "def _logits_loss(actions, logits, advantages):\n",
    "    # A trick to input actions and advantages through the same API.\n",
    "    #actions, advantages = tf.split(actions_and_advantages, 2, axis=-1)\n",
    "\n",
    "    # Sparse categorical CE loss obj that supports sample_weight arg on `call()`.\n",
    "    # `from_logits` argument ensures transformation into normalized probabilities.\n",
    "    weighted_sparse_ce = kls.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    # Policy loss is defined by policy gradients, weighted by advantages.\n",
    "    # Note: we only calculate the loss on the actions we've actually taken.\n",
    "    advantages = tf.cast([[advantages]], tf.float32)\n",
    "    actions = tf.cast(actions, tf.int32)\n",
    "    #breakpoint()\n",
    "    policy_loss = weighted_sparse_ce(actions, logits, sample_weight=advantages)\n",
    "    return policy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones(4)\n",
    "b = np.zeros(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=12, shape=(4, 1), dtype=float64, numpy=\n",
       " array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]])>, <tf.Tensor: id=13, shape=(4, 1), dtype=float64, numpy=\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.split(np.concatenate([a[:,None],b[:,None]], axis=-1), 2, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=16, shape=(1, 1), dtype=int32, numpy=array([[1]], dtype=int32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast([[1]], tf.int32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
